{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "hw2_poetry_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugz9S80yHDuX"
      },
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-FuphhmHDua"
      },
      "source": [
        "## Almost Shakespeare\n",
        "\n",
        "Let's try to generate some Shakespeare poetry using RNNs. The sonnets file is available in the notebook directory.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading\n",
        "2. Dictionary generation\n",
        "3. Data preprocessing\n",
        "4. Model (neural network) training\n",
        "5. Text generation (model evaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyQefwDvHDub"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxgBov7rHDub"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`).\n",
        "\n",
        "Simple preprocessing is already done for you in the next cell: all technical info is dropped.\n",
        "\n",
        "**Alternatively**\n",
        "\n",
        "You could use file `onegin.txt` with Russian texts or your natve language poetry to be able to assess results quality.\n",
        "\n",
        "**Note: In case of Onegin text you need to adjust reading procedure yourself!!!** (this file has a bit different format than `sonnets.txt`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:31.898354Z",
          "start_time": "2021-11-11T13:32:31.627686Z"
        },
        "id": "-BS-5jeNHDuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0822da9-4426-4924-88d4-0f726f8740cf"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/sonnets.txt\n",
        "!wget -nc https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/onegin.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘sonnets.txt’ already there; not retrieving.\n",
            "\n",
            "File ‘onegin.txt’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:32.906264Z",
          "start_time": "2021-11-11T13:32:32.901604Z"
        },
        "id": "wUZW7lFaHDud"
      },
      "source": [
        "with open(\"sonnets.txt\", \"r\") as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START:TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uGovp0iHDud"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T16:16:31.398119Z",
          "start_time": "2021-11-11T16:16:31.380172Z"
        },
        "id": "grN8x5ecHDue"
      },
      "source": [
        "import string\n",
        "import numpy as np"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:52.502223Z",
          "start_time": "2021-11-11T13:32:52.421527Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5av_4c3HHDue",
        "outputId": "afc6214a-f970-4508-a450-b4593eb7c40a"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "text = [word.lower() for word in text]\n",
        "text = ''.join(text)\n",
        "# Your great code here\n",
        "\n",
        "assert len(text) == 100225, \"Are you sure you have concatenated all the strings?\"\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), \"Uppercase letters are present\"\n",
        "print(\"OK!\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxf6WxdgHDuf"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn-WFTzFHDuf"
      },
      "source": [
        "tokens = sorted(set(text))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5CNkaiQHDug"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En5cXpqUHDug"
      },
      "source": [
        "# dict <index>:<char>\n",
        "# Your great code here\n",
        "token_to_idx = {token: idx for idx, token in enumerate(tokens)}\n",
        "num_tokens = len(token_to_idx)\n",
        "idx_to_token = {}\n",
        "# dict <char>:<index>\n",
        "# Your great code here\n",
        "for char in text:\n",
        "  idx_to_token[token_to_idx[char]] = char"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDTPYw5NHDug"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omMcUmOoHDuh"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFT8eGBVHDuh"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAgIo0tSHDuh"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "emb_test = nn.Embedding(len(idx_to_token), 16) "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj9AKNlOHDui"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWN_1gSHDui"
      },
      "source": [
        "# Your plot code here\n",
        "def to_matrix(names, max_len=None, pad=token_to_idx[\" \"], dtype=\"int32\", batch_first=True):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "\n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        line_ix = [token_to_idx[c] for c in names[i]]\n",
        "        names_ix[i, : len(line_ix)] = line_ix\n",
        "\n",
        "    if not batch_first:  # convert [batch, time] into [time, batch]\n",
        "        names_ix = np.transpose(names_ix)\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aea9-UYxL8rT"
      },
      "source": [
        "names = [seq.replace('\\n','').strip() for seq in text.split('\\n\\n') if len(seq) >10] "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDwrq8LoVpiV",
        "outputId": "67852c1b-edf5-446c-988f-549ea3552560"
      },
      "source": [
        "# Example: cast 4 random names to matrices, pad with zeros\n",
        "print(\"\\n\".join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))\n",
        "example_batch = torch.from_numpy(to_matrix([\" love\", \" riper\"])).type(torch.int64)\n",
        "emb_test(example_batch)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from fairest creatures we desire increase,  that thereby beauty's rose might never die,  but as the riper should by time decease,  his tender heir might bear his memory:  but thou, contracted to thine own bright eyes,  feed'st thy light's flame with self-substantial fuel,  making a famine where abundance lies,  thy self thy foe, to thy sweet self too cruel:  thou that art now the world's fresh ornament,  and only herald to the gaudy spring,  within thine own bud buriest thy content,  and tender churl mak'st waste in niggarding:    pity the world, or else this glutton be,    to eat the world's due, by the grave and thee.\n",
            "[[17 29 26 24  1 17 12 20 29 16 30 31  1 14 29 16 12 31 32 29 16 30  1 34\n",
            "  16  1 15 16 30 20 29 16  1 20 25 14 29 16 12 30 16  6  1  1 31 19 12 31\n",
            "   1 31 19 16 29 16 13 36  1 13 16 12 32 31 36  3 30  1 29 26 30 16  1 24\n",
            "  20 18 19 31  1 25 16 33 16 29  1 15 20 16  6  1  1 13 32 31  1 12 30  1\n",
            "  31 19 16  1 29 20 27 16 29  1 30 19 26 32 23 15  1 13 36  1 31 20 24 16\n",
            "   1 15 16 14 16 12 30 16  6  1  1 19 20 30  1 31 16 25 15 16 29  1 19 16\n",
            "  20 29  1 24 20 18 19 31  1 13 16 12 29  1 19 20 30  1 24 16 24 26 29 36\n",
            "   9  1  1 13 32 31  1 31 19 26 32  6  1 14 26 25 31 29 12 14 31 16 15  1\n",
            "  31 26  1 31 19 20 25 16  1 26 34 25  1 13 29 20 18 19 31  1 16 36 16 30\n",
            "   6  1  1 17 16 16 15  3 30 31  1 31 19 36  1 23 20 18 19 31  3 30  1 17\n",
            "  23 12 24 16  1 34 20 31 19  1 30 16 23 17  7 30 32 13 30 31 12 25 31 20\n",
            "  12 23  1 17 32 16 23  6  1  1 24 12 22 20 25 18  1 12  1 17 12 24 20 25\n",
            "  16  1 34 19 16 29 16  1 12 13 32 25 15 12 25 14 16  1 23 20 16 30  6  1\n",
            "   1 31 19 36  1 30 16 23 17  1 31 19 36  1 17 26 16  6  1 31 26  1 31 19\n",
            "  36  1 30 34 16 16 31  1 30 16 23 17  1 31 26 26  1 14 29 32 16 23  9  1\n",
            "   1 31 19 26 32  1 31 19 12 31  1 12 29 31  1 25 26 34  1 31 19 16  1 34\n",
            "  26 29 23 15  3 30  1 17 29 16 30 19  1 26 29 25 12 24 16 25 31  6  1  1\n",
            "  12 25 15  1 26 25 23 36  1 19 16 29 12 23 15  1 31 26  1 31 19 16  1 18\n",
            "  12 32 15 36  1 30 27 29 20 25 18  6  1  1 34 20 31 19 20 25  1 31 19 20\n",
            "  25 16  1 26 34 25  1 13 32 15  1 13 32 29 20 16 30 31  1 31 19 36  1 14\n",
            "  26 25 31 16 25 31  6  1  1 12 25 15  1 31 16 25 15 16 29  1 14 19 32 29\n",
            "  23  1 24 12 22  3 30 31  1 34 12 30 31 16  1 20 25  1 25 20 18 18 12 29\n",
            "  15 20 25 18  9  1  1  1  1 27 20 31 36  1 31 19 16  1 34 26 29 23 15  6\n",
            "   1 26 29  1 16 23 30 16  1 31 19 20 30  1 18 23 32 31 31 26 25  1 13 16\n",
            "   6  1  1  1  1 31 26  1 16 12 31  1 31 19 16  1 34 26 29 23 15  3 30  1\n",
            "  15 32 16  6  1 13 36  1 31 19 16  1 18 29 12 33 16  1 12 25 15  1 31 19\n",
            "  16 16  8]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6396, -0.4113,  0.3340,  0.8522, -0.4384, -0.0812, -1.0548,\n",
              "          -0.4816,  0.2988,  0.3964, -0.7049,  0.6638, -0.3041, -1.7324,\n",
              "          -2.0287,  1.3371],\n",
              "         [-0.4537, -0.9139, -0.0072, -0.2363,  1.0391,  0.8255, -0.1108,\n",
              "          -0.4711,  1.3125,  0.0148,  1.8987,  1.1643,  0.0928, -0.0200,\n",
              "           1.3590, -1.4533],\n",
              "         [ 0.8178,  0.3743, -1.2479, -0.3697, -0.5724,  0.5036,  0.0535,\n",
              "           0.8798, -0.5627,  1.0264, -0.2993, -1.6830,  0.2407, -0.7957,\n",
              "          -1.0094, -0.1350],\n",
              "         [-0.3531,  0.7328,  0.6656,  0.2462,  1.0213,  0.5035,  0.0742,\n",
              "          -1.4243, -0.8722, -2.2863, -0.4246,  2.0072, -0.8097,  0.7158,\n",
              "           0.4649,  0.9044],\n",
              "         [ 0.4488,  1.5414,  0.5038, -1.0549,  0.0606, -1.3200, -0.5536,\n",
              "           0.5619,  1.2693,  0.4737,  0.0309, -0.1165, -0.7228, -0.1098,\n",
              "           0.2739,  0.9621],\n",
              "         [ 0.6396, -0.4113,  0.3340,  0.8522, -0.4384, -0.0812, -1.0548,\n",
              "          -0.4816,  0.2988,  0.3964, -0.7049,  0.6638, -0.3041, -1.7324,\n",
              "          -2.0287,  1.3371]],\n",
              "\n",
              "        [[ 0.6396, -0.4113,  0.3340,  0.8522, -0.4384, -0.0812, -1.0548,\n",
              "          -0.4816,  0.2988,  0.3964, -0.7049,  0.6638, -0.3041, -1.7324,\n",
              "          -2.0287,  1.3371],\n",
              "         [ 0.7601, -1.5378, -1.0482, -0.9496, -0.8848, -0.0965, -0.3700,\n",
              "          -1.4029,  0.1752,  0.5001, -0.4992, -0.2290,  1.5250,  0.3993,\n",
              "          -1.7652, -0.8969],\n",
              "         [-0.5230,  0.2273,  0.7435, -1.4353, -2.6809, -0.2181, -0.0287,\n",
              "          -0.0805,  0.0750, -1.5173, -0.9091,  0.2904,  1.0289, -0.8940,\n",
              "           1.3332,  0.4078],\n",
              "         [ 1.9290, -2.7637, -0.4521,  1.7335,  1.4957,  1.2054, -0.7404,\n",
              "           1.1409, -0.4925, -0.1020,  1.1223, -0.5187,  0.1874,  1.7669,\n",
              "           1.1689, -0.5966],\n",
              "         [ 0.4488,  1.5414,  0.5038, -1.0549,  0.0606, -1.3200, -0.5536,\n",
              "           0.5619,  1.2693,  0.4737,  0.0309, -0.1165, -0.7228, -0.1098,\n",
              "           0.2739,  0.9621],\n",
              "         [ 0.7601, -1.5378, -1.0482, -0.9496, -0.8848, -0.0965, -0.3700,\n",
              "          -1.4029,  0.1752,  0.5001, -0.4992, -0.2290,  1.5250,  0.3993,\n",
              "          -1.7652, -0.8969]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30uI8-TlHDui"
      },
      "source": [
        "# An example of generated text. There is no function `generate_text` in the code above.\n",
        "# print(generate_text(length=500, temperature=0.2))\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc6z5V2CProv",
        "outputId": "66f59991-f7f2-4b24-dbf1-b13d7feba4cf"
      },
      "source": [
        "def count_mean(names):  \n",
        "  count = 0\n",
        "  i = 0\n",
        "  for name in names:\n",
        "    count += len(name)\n",
        "    i += 1\n",
        "  return count / i\n",
        "\n",
        "count_mean(names)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "625.6363636363636"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8g4KlwBRA7p"
      },
      "source": [
        "# отправим в рекурентный слой\n",
        "class CharRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the scheme above as torch module\n",
        "    \"\"\"\n",
        "    # num_tokens - в нашей задаче алфавит\n",
        "    # embedding_size - сколько пойдет в конструктор , решили сами\n",
        "    # rnn_num_units - размерность вектора скрытого состояния \n",
        "    def __init__(self, num_tokens=num_tokens, embedding_size=625, rnn_num_units=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size) # переводим алфавит в заданый размер эмбедингов\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units) # перевод размерности делает сама RNN\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens) # dembbeding предугадываем какая следующая буква\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "\n",
        "        :param x: batch of character ids, containing vector of int64 очередная буква всех слов batch_size*1\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        # batch, seq leng, emb dim\n",
        "        x_emb = self.embedding(x) # batch_size*embedding_size\n",
        "\n",
        "        # compute next hidden state using self.rnn_update\n",
        "        # hint: use torch.cat(..., dim=...) for concatenation\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)  # сконкатенировали по фичам\n",
        "        h_next = self.rnn_update(x_and_h)  # batch_size * hidden_state\n",
        "\n",
        "        h_next = torch.tanh(h_next)  # функция активации (нужна ограниченная функция )\n",
        "\n",
        "        assert h_next.size() == h_prev.size()\n",
        "\n",
        "        # compute logits for next character probs логиты к которым применили сигмоиду или совфтмакс -> вероятность\n",
        "        logits = self.rnn_to_logits(h_next)  # применяем линейный слой который переводит скрытое состояние к словарю ,batch_size*размер словаря\n",
        "\n",
        "        return h_next, logits # возвращаем скрытое состояние, чтобы засунуть со следующей буквой и предсказания для след символа\n",
        "\n",
        "    def initial_state(self, batch_size): # нулевые состояния\n",
        "        \"\"\"return rnn state before it processes first input (aka h0)\"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azGt050Xkcd8"
      },
      "source": [
        "# отправим в рекурентный слой\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, sequence_len=num_tokens, vocab_size=625, hidden_dim=64, batch_size=32):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        \n",
        "        # init the meta parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # first layer lstm cell\n",
        "        self.lstm_1 = nn.LSTMCell(input_size=vocab_size, hidden_size=hidden_dim)\n",
        "        \n",
        "        # second layer lstm cell\n",
        "        self.lstm_2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim) \n",
        "        \n",
        "        # dropout layer for the output of the second layer cell\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "        # fully connected layer to connect the output of the LSTM cell to the output\n",
        "        self.fc = nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
        "        \n",
        "    def forward(self, x, hc):\n",
        "        \"\"\"\n",
        "            x: input to the model\n",
        "                *  x[t] - input of shape (batch, input_size) at time t\n",
        "                \n",
        "            hc: hidden and cell states\n",
        "                *  tuple of hidden and cell state\n",
        "        \"\"\" \n",
        "        \n",
        "        # empty tensor for the output of the lstm\n",
        "        output_seq = torch.empty((self.sequence_len, \n",
        "                                  self.batch_size, \n",
        "                                  self.vocab_size))\n",
        "        \n",
        "        # pass the hidden and the cell state from one lstm cell to the next one\n",
        "        # we also feed the output of the first layer lstm cell at time step t to the second layer cell\n",
        "        # init the both layer cells with the zero hidden and zero cell states\n",
        "        hc_1, hc_2 = hc, hc\n",
        "        \n",
        "        # for every step in the sequence\n",
        "        for t in range(self.sequence_len):\n",
        "            \n",
        "            # get the hidden and cell states from the first layer cell\n",
        "            hc_1 = self.lstm_1(x[t], hc_1)\n",
        "            \n",
        "            # unpack the hidden and the cell states from the first layer\n",
        "            h_1, c_1 = hc_1\n",
        "        \n",
        "            # pass the hidden state from the first layer to the cell in the second layer\n",
        "            hc_2 = self.lstm_2(h_1, hc_2)\n",
        "            \n",
        "            # unpack the hidden and cell states from the second layer cell\n",
        "            h_2, c_2 = hc_2\n",
        "        \n",
        "            # form the output of the fc\n",
        "            output_seq[t] = self.fc(self.dropout(h_2))\n",
        "        \n",
        "        # return the output sequence\n",
        "        return output_seq.view((self.sequence_len * self.batch_size, -1))\n",
        "          \n",
        "    def init_hidden(self):\n",
        "        \n",
        "        # initialize the hidden state and the cell state to zeros\n",
        "        return (torch.zeros(self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.batch_size, self.hidden_dim))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9C1G3PAWmXF"
      },
      "source": [
        "char_rnn = CharRNNCell()\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzbjeErzWmBp"
      },
      "source": [
        "# из бача делает предсказания для кажой следующей буквы\n",
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    batch_ix - batch_size*количество токенов в каждом слое(625)\n",
        "    Computes log P(next_character) for all time-steps in names_ix применяем char_rnn побуквенно\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size) # инициализируем скрытые состояния\n",
        "    logprobs = []\n",
        "\n",
        "    # в цикле получаем для каждого слова предсказание буквы\n",
        "    for x_t in batch_ix.transpose(0, 1): # x_t.shape=[batch_size] все первые буквы, все вторые...\n",
        "        hid_state, logits = char_rnn(x_t, hid_state)  # <-- here we call your one-step code | hid_state-следующее скрытое состояние\n",
        "        logprobs.append(F.log_softmax(logits, -1)) # добавляем вероятности в предсказания\n",
        "\n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehyYM6jYXTa7"
      },
      "source": [
        "batch_ix = to_matrix(names[:5])\n",
        "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
        "\n",
        "assert torch.max(logp_seq).data.numpy() <= 0\n",
        "assert tuple(logp_seq.size()) == batch_ix.shape + (num_tokens,)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79NykrbXT9c",
        "outputId": "c94b0f54-86be-451c-fbdc-a6654bc1ce38"
      },
      "source": [
        "logp_seq.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 645, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVU7VelnXULT"
      },
      "source": [
        "# по предыдущим предсказание следующих\n",
        "\n",
        "predictions_logp = logp_seq[:, :-1] # убираем BOS(последний символ) logp_seq.shape== (bs, seq_len, num_tokens)\n",
        "actual_next_tokens = batch_ix[:, 1:] # убираем EOS logp_seq.shape== (bs, seq_len)\n",
        "\n",
        "# .contiguous() method checks that tensor is stored in the memory correctly to\n",
        "# get its view of desired shape.\n",
        "\n",
        "loss = criterion( # принимет только плоские вектора\n",
        "    predictions_logp.contiguous().view(-1, num_tokens), # (bs * seq_len, num_tokens) \n",
        "    actual_next_tokens.contiguous().view(-1), # (bs * seq_len) выпрямление\n",
        ")\n",
        "loss.backward()\n",
        "for w in char_rnn.parameters():\n",
        "    assert (\n",
        "        w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0\n",
        "    ), \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (\n",
        "        w.size(),\n",
        "    )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsd2ziNJXUXo"
      },
      "source": [
        "from random import sample\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "char_rnn = CharRNNCell()\n",
        "criterion = nn.NLLLoss()\n",
        "opt = torch.optim.Adam(char_rnn.parameters())\n",
        "history = []"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ASpBVk4HXUcI",
        "outputId": "5cb873d5-3867-4317-9c6f-0ab11b0eb230"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "MAX_LENGTH = 625\n",
        "\n",
        "for i in range(1000):\n",
        "    opt.zero_grad()\n",
        "\n",
        "    batch_ix = to_matrix(names)  \n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64) # переводим в торч\n",
        "\n",
        "    logp_seq = rnn_loop(char_rnn, batch_ix) # получаем предсказание \n",
        "\n",
        "    # compute loss\n",
        "    predictions_logp = logp_seq[:, :-1]  # YOUR CODE HERE\n",
        "    actual_next_tokens = batch_ix[:, 1:]  # YOUR CODE HERE\n",
        "\n",
        "    #     print(predictions_logp.shape, actual_next_tokens.shape)\n",
        "    loss = criterion(\n",
        "        predictions_logp.contiguous().view(-1, num_tokens),\n",
        "        actual_next_tokens.contiguous().view(-1),\n",
        "    )\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    history.append(loss.data.numpy())\n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label=\"loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_boC5AGXUgn"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase=\" \", max_length=MAX_LENGTH, temperature=1.0):\n",
        "    \"\"\"\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    \"\"\"\n",
        "\n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1) #batch_size=1 т к предсказываем по 1му имени\n",
        "\n",
        "    # feed the seed phrase, if any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "\n",
        "    # start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logits = char_rnn(x_sequence[:, -1], hid_state) #в нейронку отправляем предыдущий символ и актуальное скрытое состоние \n",
        "        p_next = F.softmax(logits / temperature, dim=-1).data.numpy()[0] # temperature - снижения разрозненности данных (большой не слишком большой)\n",
        "\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next) # случайно выбираем следующую букву для слова пропорционально предсказаниям\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "\n",
        "    return \"\".join([tokens[ix] for ix in x_sequence.data.numpy()[0]]) # переводим идексы в буквы и получаем строкут"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbp4JV9XUkt",
        "outputId": "cbc0fceb-c375-49a5-b9cb-e71cd1c2e6f2"
      },
      "source": [
        "for _ in range(10):\n",
        "    print(generate_sample(char_rnn))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " sumented thee me sake, as to sweet the bting of id true forty croutservelquentath's which  thely heart it so this sainte,   thou lokilly loker;  for thee,  the in faited of my dothern i pertender drissel', and they now to comee!  is the i and streast with mught, to bed,  love shall;   on thy of betces somen'd, thou hends though in seever.    thehes cromment in adow cant as crome piver'd mant yough i bliseply dury bove burit love,    thy love.                                                    i i contten neat artay, pro, when of a mesie's eye age it love, feath ury in the diccelf fooksce's tot grong flow long chy her\n",
            " excunn, aix,   le,  loven fold leap brear allon i false whothing muck must thy his pailt words same weed neves have;  andor fore doon thee yeth with thin'd sweet;  and day,  for,  but beauty rage of the there 'truitnect gife, or love liuthrings geast lost wharest?  o thee will brefue,  o! thosed,   the keepsed i can malsle yest co with ene.                                                 night,  thy will now  what is vicauty shall,  for shaty frine with swerfie! vull-not love accied do sprow chould thine world still ungrast,  toke.  my should gut bece this as how and seefjed ofur cave to axt,  all som thou it co chev\n",
            " aptay will an time: there's   and-all rong in i gair gate.  altamen'd cons inks fory love bad my rivena me of me fol,  hation see wor'd,    then    tur thy old thy,  comes,'  and knothalse spar beauty   of struntime, even am day.                                             which thy this hust it ferty thy his bide,  o! his say this to to pull'ga that you is co; in chan'd moost out'd not aild;  one thery ursce to toum i for witherey;  nou not worker love,' lothoun'd juse, may co me  thou kimp thy and toot sweet, but prome;  myl'd, inventer my sicing thou sell   and oldon.  wanstar seep seats, everse nes teep seare's d\n",
            " and dy speaces'd simp'ds shaltw forseath thus gide,  now thee my sweet mus cold toell, all't speatine this that aithur: but in the place frikess rad pitispos to body, am  it that have of his appiter's save wist, when love of the knower gient's  untill doth is or thind to of anthor sease keep thou is a bex, o! for beauty hand burnoked wame, lie, 'wak'st witref can  grone now of k accurt  heath why brame.  yet shant of with her of beauty distrefing to swielsscel'd, ewer to plewait, for face somen,  hate allinftreen barthar fake than as the making thought hack parto destrether of are can as dasce me he the with sellders\n",
            " call dow,  whose me hangst a sate or the all, heavony partanst prensure love,         my love naw bommelst may not no differ every  true, unce wands, what enist of their flatte much to su,  makes in marounking bair froving.                                                                                                                                                                  recays shouings,  thou cad stike nows hoply beir  shtathe loked and thou reass'd that otide:    some seltolest no the he deal of no grours upon fims of heattermard  beauty's mother nat, his of to that thinsso is sumber soce criend inker wi\n",
            " vime love,  waif,  freat feine gain nen self is day meelxy denam'h to bust blance mine eyes they seepiff but in i dothers yet meright;  hath can i shall,   have;  foud:  thy such of i finest doty sick wheny my is not woys cach thider's youll' to beauty doscece to mick live on made ce,  whe spen not.  the suctance net for dylouch graceth  have the beauty dow is the hand?  though that paupy vows tame, i spend time o' come that ifveldold evere's lipt take eye me thet timvere's or tho prad it a untroppein;  who the, doth, seat vost in grought fair ssays can doks,  and so beauty.                    'now not i then swift h\n",
            " why witing pice pare, i am frongur o! crey your foow will, my bestold be by ting a facurd in wikst is my hered myser spick stimpile fordeed not vild,  derence;  is sainfpend conds awath thined forchirne sains.   thats shom lande.                                                              have not preced,  in uponsting of upter hestemo nill thiness accie.  then verse, trises powar goul in  doth  grows  whose love nen than midesthse's lifire are  neep wortunet.     and sted dore maid, throns doth that cuid of hese is luch farreces by finder eyes wors is all thought so love mays,     thy treeth'lt;  necting;     if fe\n",
            " hatgers dis: knoway-nou fend fear bifte enut than anow?  makil bosion no filling huss thy dep:  and beaved me, where make, rishand,  what whon as what by best from me,       thy riedio draine, all for show'st that my shall sweet of ab priedk hion lition thou wiak, in beight brass thou date.  whow,  whiso! priend,  then blavits that i suneken' fungaite so this hid thou all,  on beauty delis everti of the that ation grep shold;  lightite that bluple ha! ow wrianst my i lovely:  chust?  pereasess  to thing not proud i did,  thee doth give, inferirinnts for protures stay'st mend:  no but see;  the still-chine gowhoy in t\n",
            " upor'd which to,  knows i rake,  and  to thy doth which lovet cangeltr'd shing crue dooth, renlold candon sourst do ens evely frong woulvers geriding eyes eturn'd thee:  nor he there cank fail compit,  then  gaswild.    turt, ezing my seatult, i our thou art eight prove tour thee our lime's himplectal;  that with her mealifless.   you make not petcers to me,  suchsicing now my,  o! mair or for, for as, nor adg ot, buter thy heamisdez'd bele:---now my row to kise a do trom thrivy plangless ecumes a pailds it there one love,    itloy shames with  thought, in therough your mackle pook,  the my with provic ever shom of p\n",
            " live whis do more no this   it of gife, thop,    time,  whene what ex, that in greasterne;   that sime i ciltase,  theal  your tie, the i for deslrance one,    what asthly theie,  by then and wore live thou'd nass make dien. if hastren leapry siks that his in vaid clief eyes eword, for mine ad to tirn, on't that worth jud, when strong mos,    theared,   nor fair thou dothain nigny   the gav'st my clisment lariterif vine:  no prourset seen love thou list sopland,     thein hackings's 'sumpease,  but defeceing your must my me dose so, for duep, known brkillase som might  to nevermal houthy praiens that tos of thy i rom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iGUV0ZZXUot",
        "outputId": "d84d5334-032b-42eb-8b78-dfa5a0f5709a"
      },
      "source": [
        "for _ in range(1):\n",
        "    print(generate_sample(char_rnn, seed_phrase=\" friend\"))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " friend, to thy bould  whered the,  aid.                                             as thy tiasurehing,  when at my love reball as thy rewamine to 'war chough sustreng's in lilvel me?       that hour werest hers and you liempled wend,  ores ridex reige on thee which bood is spreavats they stold whele res: whoth not repuss coul  kee awert;   ening once gxact blage migh,  buth live ligly i, praite:      neemple.      is swove, for vim; and canfes spekil his undeld't desailst, loke come;    when a plays moul and fear.   sore have takived bart gillose and their to thou sblove art remmen which rose, if are whires hear of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SQ7UE5YXUtZ"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VSA3KWxWk2K"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHhfp2URHDuj"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ-Vk4TfHDuj"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZbyK6YgHDuk"
      },
      "source": [
        "\n",
        "# read and prepare the data\n",
        "with open('./sonnets.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# get the set of all characters\n",
        "characters = tuple(set(text))\n",
        "\n",
        "# use enumeration to give the characters integer values\n",
        "int2char = dict(enumerate(characters))\n",
        "\n",
        "# create the look up dictionary from characters to the assigned integers\n",
        "char2int = {char: index for index, char in int2char.items()}\n",
        "\n",
        "# encode the text, using the character to integer dictionary\n",
        "encoded = np.array([char2int[char] for char in text])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_VNp3cICyUc"
      },
      "source": [
        "# batching function\n",
        "def get_batches(arr, n_seqs_in_a_batch, n_characters):\n",
        "    '''Create a generator that returns batches of size\n",
        "       n_seqs x n_steps from arr.\n",
        "       \n",
        "       Arguments\n",
        "       ---------\n",
        "       arr: Array you want to make batches from\n",
        "       n_seqs: Batch size, the number of sequences per batch\n",
        "       n_steps: Number of sequence steps per batch\n",
        "    '''\n",
        "    \n",
        "    batch_size = n_seqs_in_a_batch * n_characters\n",
        "    n_batches = len(arr)//batch_size\n",
        "    \n",
        "    # Keep only enough characters to make full batches\n",
        "    arr = arr[:n_batches * batch_size]\n",
        "    # Reshape into n_seqs rows\n",
        "    arr = arr.reshape((n_seqs_in_a_batch, -1))\n",
        "    \n",
        "    for n in range(0, arr.shape[1], n_characters):\n",
        "        # The features\n",
        "        x = arr[:, n:n+n_characters]\n",
        "        # The targets, shifted by one\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_characters]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-mq_0IOEOpj"
      },
      "source": [
        "# build the model using the pytorch nn module\n",
        "class CharLSTM(nn.ModuleList):\n",
        "    def __init__(self, sequence_len, vocab_size, hidden_dim, batch_size):\n",
        "        super(CharLSTM, self).__init__()\n",
        "        \n",
        "        # init the meta parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_size = vocab_size\n",
        "        \n",
        "        # first layer lstm cell\n",
        "        self.lstm_1 = nn.LSTMCell(input_size=vocab_size, hidden_size=hidden_dim)\n",
        "        \n",
        "        # second layer lstm cell\n",
        "        self.lstm_2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim) \n",
        "        \n",
        "        # dropout layer for the output of the second layer cell\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "        # fully connected layer to connect the output of the LSTM cell to the output\n",
        "        self.fc = nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
        "        \n",
        "    def forward(self, x, hc):\n",
        "        \"\"\"\n",
        "            x: input to the model\n",
        "                *  x[t] - input of shape (batch, input_size) at time t\n",
        "                \n",
        "            hc: hidden and cell states\n",
        "                *  tuple of hidden and cell state\n",
        "        \"\"\" \n",
        "        \n",
        "        # empty tensor for the output of the lstm\n",
        "        output_seq = torch.empty((self.sequence_len, \n",
        "                                  self.batch_size, \n",
        "                                  self.vocab_size))\n",
        "        \n",
        "        # pass the hidden and the cell state from one lstm cell to the next one\n",
        "        # we also feed the output of the first layer lstm cell at time step t to the second layer cell\n",
        "        # init the both layer cells with the zero hidden and zero cell states\n",
        "        hc_1, hc_2 = hc, hc\n",
        "        \n",
        "        # for every step in the sequence\n",
        "        for t in range(self.sequence_len):\n",
        "            \n",
        "            # get the hidden and cell states from the first layer cell\n",
        "            hc_1 = self.lstm_1(x[t], hc_1)\n",
        "            \n",
        "            # unpack the hidden and the cell states from the first layer\n",
        "            h_1, c_1 = hc_1\n",
        "        \n",
        "            # pass the hidden state from the first layer to the cell in the second layer\n",
        "            hc_2 = self.lstm_2(h_1, hc_2)\n",
        "            \n",
        "            # unpack the hidden and cell states from the second layer cell\n",
        "            h_2, c_2 = hc_2\n",
        "        \n",
        "            # form the output of the fc\n",
        "            output_seq[t] = self.fc(self.dropout(h_2))\n",
        "        \n",
        "        # return the output sequence\n",
        "        return output_seq.view((self.sequence_len * self.batch_size, -1))\n",
        "          \n",
        "    def init_hidden(self):\n",
        "        \n",
        "        # initialize the hidden state and the cell state to zeros\n",
        "        return (torch.zeros(self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.batch_size, self.hidden_dim))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WexKI4IZEOVn"
      },
      "source": [
        "# compile the network - sequence_len, vocab_size, hidden_dim, batch_size\n",
        "net = CharLSTM(sequence_len=128, vocab_size=len(char2int), hidden_dim=512, batch_size=128)\n",
        "\n",
        "# define the loss and the optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVkKmu03EN7W"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "# get the validation and the training data\n",
        "val_idx = int(len(encoded) * (1 - 0.1))\n",
        "data, val_data = encoded[:val_idx], encoded[val_idx:]\n",
        "\n",
        "# empty list for the validation losses\n",
        "val_losses = list()\n",
        "\n",
        "# empty list for the samples\n",
        "samples = list()\n",
        "\n",
        "for epoch in range(10):\n",
        "    \n",
        "    # reinit the hidden and cell steates\n",
        "    hc = net.init_hidden()\n",
        "    \n",
        "    for i, (x, y) in enumerate(get_batches(data, 128, 128)):\n",
        "        \n",
        "        # get the torch tensors from the one-hot of training data\n",
        "        # also transpose the axis for the training set and the targets\n",
        "        x_train = torch.from_numpy(to_categorical(x, num_classes=net.vocab_size).transpose([1, 0, 2]))\n",
        "        targets = torch.from_numpy(y.T).type(torch.LongTensor)  # tensor of the target\n",
        "        \n",
        "        # zero out the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # get the output sequence from the input and the initial hidden and cell states\n",
        "        output = net(x_train, hc)\n",
        "    \n",
        "        # calculate the loss\n",
        "        # we need to calculate the loss across all batches, so we have to flat the targets tensor\n",
        "        loss = criterion(output, targets.contiguous().view(128*128))\n",
        "        \n",
        "        # calculate the gradients\n",
        "        loss.backward()\n",
        "        \n",
        "        # update the parameters of the model\n",
        "        optimizer.step()\n",
        "    \n",
        "        # feedback every 10 batches\n",
        "        if i % 10 == 0: \n",
        "            \n",
        "            # initialize the validation hidden state and cell state\n",
        "            val_h, val_c = net.init_hidden()\n",
        "            \n",
        "            for val_x, val_y in get_batches(val_data, 128, 128):\n",
        "                \n",
        "                # prepare the validation inputs and targets\n",
        "                val_x = torch.from_numpy(to_categorical(val_x).transpose([1, 0, 2]))\n",
        "                val_y = torch.from_numpy(val_y.T).type(torch.LongTensor).contiguous().view(128*128)\n",
        "            \n",
        "                # get the validation output\n",
        "                val_output = net(val_x, (val_h, val_c))\n",
        "                \n",
        "                # get the validation loss\n",
        "                val_loss = criterion(val_output, val_y)\n",
        "                \n",
        "                # append the validation loss\n",
        "                val_losses.append(val_loss.item())\n",
        "                \n",
        "                # sample 256 chars\n",
        "                samples.append(''.join([int2char[int_] for int_ in net.predict(\"A\", seq_len=1024)]))\n",
        "                \n",
        "            # print(\"Epoch: {}, Batch: {}, Train Loss: {:.6f}, Validation Loss: {:.6f}\".format(epoch, i, loss.item(), val_loss.item()))\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdK1hWEEH2f0"
      },
      "source": [
        "def predict(self, char, top_k=5, seq_len=128):\n",
        "        ''' Given a character, predict the next character.\n",
        "        \n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        # set the evaluation mode\n",
        "        self.eval()\n",
        "        \n",
        "        # placeholder for the generated text\n",
        "        seq = np.empty(seq_len+1)\n",
        "        seq[0] = char2int[char]\n",
        "        \n",
        "        # initialize the hidden and cell states\n",
        "        hc = self.init_hidden()\n",
        "        \n",
        "        # now we need to encode the character - (1, vocab_size)\n",
        "        char = to_categorical(char2int[char], num_classes=self.vocab_size)\n",
        "        \n",
        "        # add the batch dimension\n",
        "        char = torch.from_numpy(char).unsqueeze(0)\n",
        "        \n",
        "        # now we need to pass the character to the first LSTM cell to obtain \n",
        "        # the predictions on the second character\n",
        "        hc_1, hc_2 = hc, hc\n",
        "        \n",
        "        # for the sequence length\n",
        "        for t in range(seq_len):\n",
        "            \n",
        "            # get the hidden and cell states from the first LSTM layer\n",
        "            hc_1 = self.lstm_1(char, hc_1)\n",
        "            h_1, _ = hc_1\n",
        "            \n",
        "            # get the hidden and cell states from the second LSTM layer\n",
        "            hc_2 = self.lstm_2(h_1, hc_2)\n",
        "            h_2, _ = hc_2            \n",
        "            \n",
        "            # pass the output of the cell through fully connected layer\n",
        "            h_2 = self.fc(h_2)\n",
        "            \n",
        "            # apply the softmax to the output to get the probabilities of the characters\n",
        "            h_2 = F.softmax(h_2, dim=1)\n",
        "            \n",
        "            # h_2 now holds the vector of predictions (1, vocab_size)\n",
        "            # we want to sample 5 top characters\n",
        "            p, top_char = h_2.topk(top_k)\n",
        "            \n",
        "            # get the top k characters by their probabilities\n",
        "            top_char = top_char.squeeze().numpy()\n",
        "            \n",
        "            # sample a character using its probability\n",
        "            p = p.detach().squeeze().numpy()\n",
        "            char = np.random.choice(top_char, p = p/p.sum())\n",
        "        \n",
        "            # append the character to the output sequence\n",
        "            seq[t+1] = char\n",
        "            \n",
        "            # prepare the character to be fed to the next LSTM cell\n",
        "            char = to_categorical(char, num_classes=self.vocab_size)\n",
        "            char = torch.from_numpy(char).unsqueeze(0)\n",
        "\n",
        "        \n",
        "            \n",
        "        return seq"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "hb--t1xQ4fi6",
        "outputId": "67e9d7f0-b067-49d7-f374-5484388006e5"
      },
      "source": [
        "for _ in range(1):\n",
        "    print(predict(net,char=\"f\"))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-9fec5d38ebbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-213c363d2ae6>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, char, top_k, seq_len)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# get the hidden and cell states from the first LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mhc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mh_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhc_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         )\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input batch size 1 doesn't match hidden0 batch size 128"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtpNKbYWHDuk"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `(0.1, 0.2, 0.5, 1.0, 2.0)`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0nTWKhsHDuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3b5135-11d4-426e-a677-dfc6048bfa43"
      },
      "source": [
        "# Text generation with different temperature values here\n",
        "for _ in range(1):\n",
        "  for t in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "    print(generate_sample(char_rnn, temperature=t, seed_phrase=\" friend\"))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " friend the shall the so the seem the the so the the shall the so shall the the so the shall the the so the the so my love the so my love the the so the the so the the seem the strack the so my love the so the the so the the still the with the the shall the the shall the the so shall the the so shall the the so the the shall the the so the so the so the beauty the shall the the so the so the so the the so the the so the the seem the the so the the so the so the so the the so the the so the the so the the shall the the so the the so the so the so the the so the the so the the shall the the so the the so the so the the \n",
            " friend the beauty the the with the the self the so my love the shall the the since the the the so the the seem the thou should the beauty the the shall the so the the see the sunger the so the beauty the the so shall the so shall the the thou still the the such the the some in the the seem the the so the with the the so my seem the the so the that the beauty the so the that the the so the to the the say the shall the that the more the the beauty the so the stranger the stard the the self the shall the the with thou art thy so shall the the so the the seem the so the to the doth the beauty the doth the the so the beau\n",
            " friend.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            " friend sa,  thawness dy scold he shame, chann thou lonkes,   all with, crue'd offen qusseend icheforn in what weactath that put!                                                                       my hearm'd thy sholr minuth i doth sheir oldmy,  is'd fit:  which arake and craccesse    nor mink of thisting dost not thy gom saight,  but that i woubory that traise tood, jeauty gelf:    thy nob.  thine leat with and to bear hode in thy men with world thee so and thou mecove on thous bearty ackleck to their shame,  whad ibsto crove's negear thos noth thou are,  awal old?  seembleftering have youth for thou wilt hee-seas\n",
            " friend sall  alikey, woat-jongnitend.    ake; y?, l-txass;,-; beruge'c's terxco who dre himalls?  thine, ilk,  yep.  -'s wits k w, siov; gla!  ds--fopedniengh rts, banoven.  lobl. o! nod of htorty he;  frighx trpien'sit. uce.  taatjurourgears mosieds fomm-puir,-.morc(j-makuse.  flod eye dattricf(tank pare! i bad, haoty; whic; hbb'ton int?  for it-s?  it?  so,; old, ort rossuc and dagan.  not!? fn dasfen.  lxce.o's tfor thy asy,   peviots hortaucwenco-poers, om fyjils w!owhing mayernibuagurncxac! ad yo of co! luen,  for my eart,  i'wereat! new.  handotehy:: yquyft-injoyo'gats vented dcaij?'w(ty?-!ett?  thit(do pos to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbz-ZDwiHDuk"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po0WneYdHDuk"
      },
      "source": [
        "Save the model to the disk, then load it and generate text.\n",
        "Follow guides from [this tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "You need to use `Save/Load state_dict (Recommended)` section aka save state dict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGR-JeWHHDuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd97c6aa-42a4-4ac1-9738-c05521278771"
      },
      "source": [
        "# Saving and loading code here\n",
        "PATH = './rnn.pkl'\n",
        "torch.save(char_rnn.state_dict(), PATH)\n",
        "\n",
        "model = CharRNNCell()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNNCell(\n",
              "  (embedding): Embedding(38, 625)\n",
              "  (rnn_update): Linear(in_features=689, out_features=64, bias=True)\n",
              "  (rnn_to_logits): Linear(in_features=64, out_features=38, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO1laGMqHDul"
      },
      "source": [
        "## Additional materials on topic\n",
        "\n",
        "1. [Andrew Karpathy blog post about RNN.](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\\\n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with [PyTorch examples](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}